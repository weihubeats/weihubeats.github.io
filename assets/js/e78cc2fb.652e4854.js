"use strict";(globalThis.webpackChunkweihubeats_website=globalThis.webpackChunkweihubeats_website||[]).push([[4443],{59668(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"MQ/Kafka/\u8fd0\u7ef4\u90e8\u7f72/KRaft\u96c6\u7fa4\u642d\u5efa","title":"KRaft\u96c6\u7fa4\u642d\u5efa","description":"\u5bb9\u91cf\u8bc4\u4f30","source":"@site/docs/MQ/Kafka/\u8fd0\u7ef4\u90e8\u7f72/KRaft\u96c6\u7fa4\u642d\u5efa.md","sourceDirName":"MQ/Kafka/\u8fd0\u7ef4\u90e8\u7f72","slug":"/MQ/Kafka/\u8fd0\u7ef4\u90e8\u7f72/KRaft\u96c6\u7fa4\u642d\u5efa","permalink":"/docs/MQ/Kafka/\u8fd0\u7ef4\u90e8\u7f72/KRaft\u96c6\u7fa4\u642d\u5efa","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/MQ/Kafka/\u8fd0\u7ef4\u90e8\u7f72/KRaft\u96c6\u7fa4\u642d\u5efa.md","tags":[],"version":"current","lastUpdatedAt":1757919008000,"frontMatter":{},"sidebar":"MQ_Kafka","previous":{"title":"Kafka\u96c6\u7fa4\u76d1\u63a7\u8c03\u7814\u5b9e\u6218","permalink":"/docs/MQ/Kafka/\u76d1\u63a7/Kafka\u96c6\u7fa4\u76d1\u63a7\u8c03\u7814\u5b9e\u6218"},"next":{"title":"Kafka Linux\u7cfb\u7edf\u53c2\u6570\u4f18\u5316\u811a\u672c","permalink":"/docs/MQ/Kafka/\u8fd0\u7ef4\u90e8\u7f72/Kafka Linux\u7cfb\u7edf\u53c2\u6570\u4f18\u5316\u811a\u672c"}}');var r=t(74848),s=t(28453);const i={},a=void 0,l={},c=[{value:"\u5bb9\u91cf\u8bc4\u4f30",id:"\u5bb9\u91cf\u8bc4\u4f30",level:2},{value:"\u673a\u5668",id:"\u673a\u5668",level:2},{value:"\u914d\u7f6e\u6587\u4ef6",id:"\u914d\u7f6e\u6587\u4ef6",level:2},{value:"controller",id:"controller",level:3},{value:"controller1",id:"controller1",level:4},{value:"controller2",id:"controller2",level:4},{value:"controller3",id:"controller3",level:4},{value:"broker",id:"broker",level:3},{value:"broker1",id:"broker1",level:4},{value:"broker2",id:"broker2",level:4},{value:"\u90e8\u7f72",id:"\u90e8\u7f72",level:2},{value:"1. \u5b89\u88c5jdk11",id:"1-\u5b89\u88c5jdk11",level:3},{value:"2. \u4e0b\u8f7dkafka\u4e8c\u8fdb\u5236\u5305",id:"2-\u4e0b\u8f7dkafka\u4e8c\u8fdb\u5236\u5305",level:3},{value:"3. \u89e3\u538b",id:"3-\u89e3\u538b",level:3},{value:"4. \u7ed9\u96c6\u7fa4\u751f\u6210\u4e00\u4e2aUUID",id:"4-\u7ed9\u96c6\u7fa4\u751f\u6210\u4e00\u4e2auuid",level:3},{value:"5. \u4fee\u6539\u914d\u7f6e\u6587\u4ef6",id:"5-\u4fee\u6539\u914d\u7f6e\u6587\u4ef6",level:3},{value:"6. \u542f\u52a8\u96c6\u7fa4",id:"6-\u542f\u52a8\u96c6\u7fa4",level:3},{value:"\u542f\u52a8controller",id:"\u542f\u52a8controller",level:4},{value:"\u542f\u52a8broker",id:"\u542f\u52a8broker",level:4},{value:"\u63a5\u5165\u70b9",id:"\u63a5\u5165\u70b9",level:2},{value:"\u5220\u9664\u5143\u6570\u636e",id:"\u5220\u9664\u5143\u6570\u636e",level:2},{value:"\u6d4b\u8bd5",id:"\u6d4b\u8bd5",level:2}];function h(e){const n={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"\u5bb9\u91cf\u8bc4\u4f30",children:"\u5bb9\u91cf\u8bc4\u4f30"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"qps:\u5047\u8bbeqps1000\u5de6\u53f3"}),"\n",(0,r.jsx)(n.li,{children:"\u78c1\u76d8: \u5047\u8bbe\u6bcf\u5929\u6d88\u606f\u91cf1000w\u5de6\u53f3\uff0c\u6bcf\u6761\u6d88\u606f\u5927\u5c0f2M\uff0c\u6d88\u606f\u4fdd\u5b58\u65f6\u95f4\u4e3a14\u5929\u3002\u526f\u672c\u4e3a2\u4e2a\u3002\u90a3\u4e48\u603b\u7684\u78c1\u76d8\u7a7a\u95f4\u4e3a 1000w * 2M * 14 * 2 / 1024 = 54g\u5de6\u53f3\uff0c\u8fd8\u6709\u5176\u4ed6\u7d22\u5f15\u6570\u636e\u5565\u7684\uff0c\u9884\u755910% \u5927\u698250~60g\u5de6\u53f3\uff0c\u6240\u4ee5\u6682\u65f6100g\u591f\u7528\u3002\u78c1\u76d8\u6269\u5bb9\u6bd4\u4ef7\u65b9\u4fbf"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"\u673a\u5668",children:"\u673a\u5668"}),"\n",(0,r.jsx)(n.p,{children:"\u6240\u4ee5\u6682\u65f6\u9009\u77405\u53f0\u673a\u5668\u90e8\u7f72"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"3\u53f0\u90e8\u7f72KRaft"}),"\n",(0,r.jsx)(n.li,{children:"2\u53f0\u90e8\u7f72broker"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u673a\u5668\u914d\u7f6e\u6682\u65f6\u90fd\u662f4\u683816g\uff0c\u78c1\u76d8100g"}),"\n",(0,r.jsx)(n.p,{children:"\u5047\u8bbe\u6211\u4eec\u7684\u673a\u5668ip\u662f"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{style:{textAlign:"center"},children:"\u673a\u5668"}),(0,r.jsx)(n.th,{style:{textAlign:"center"},children:"ip"}),(0,r.jsx)(n.th,{style:{textAlign:"center"},children:"\u57df\u540d"}),(0,r.jsx)(n.th,{style:{textAlign:"center"},children:"\u90e8\u7f72\u89d2\u8272"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"1"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"192.168.1.1"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"kafka-controller-prd-001.com"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"controller"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"2"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"192.168.1.2"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"kafka-controller-prd-002.com"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"controller"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"3"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"192.168.1.3"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"kafka-controller-prd-003.com"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"controller"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"4"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"192.168.1.4"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"kafka-prd-001.com"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"broker"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"5"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"192.168.1.5"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"kafka-prd-002.com"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"broker"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:["\u6ce8\u610f\u6240\u6709\u673a\u5668\u7684",(0,r.jsx)(n.code,{children:"9092"}),"\u3001",(0,r.jsx)(n.code,{children:"9093"}),"\u3001",(0,r.jsx)(n.code,{children:"9099"}),"\u7aef\u53e3\u90fd\u6253\u5f00"]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"\u6ce8\u610f\u4e3a\u4e86\u4fdd\u8bc1\u9ad8\u53ef\u7528\u6700\u597d\u4fdd\u8bc1\u90e8\u7f72broker\u548ccontroller\u4e0d\u540c\u526f\u672c\u5728\u4e0d\u540c\u7684\u53ef\u7528\u533a"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"\u914d\u7f6e\u6587\u4ef6",children:"\u914d\u7f6e\u6587\u4ef6"}),"\n",(0,r.jsx)(n.h3,{id:"controller",children:"controller"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"controller2"}),"\u548c",(0,r.jsx)(n.code,{children:"controller3"}),"\u7684\u914d\u7f6e\u548c",(0,r.jsx)(n.code,{children:"controller1"}),"\u5176\u5b9e\u662f\u5dee\u4e0d\u591a\u7684\uff0c\u53ea\u4e0d\u8fc7",(0,r.jsx)(n.code,{children:"node.id"}),"\u4e0d\u540c\uff0c\u5176\u6b21\u662f",(0,r.jsx)(n.code,{children:"listeners"}),"\u8981\u5bf9\u5e94\u81ea\u5df1\u7684\u57df\u540d"]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["\u6ce8\u610f",(0,r.jsx)(n.code,{children:"node.id"}),"\u4e2d\u7684",(0,r.jsx)(n.code,{children:"id"}),"\u548c",(0,r.jsx)(n.code,{children:"controller.quorum.voters"}),"\u4e2d\u7684\u6570\u5b57\u8981\u5bf9\u5e94\u4e0a"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"controller1",children:"controller1"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the "License"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an "AS IS" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in KRaft mode, where\n# Apache ZooKeeper is not present.\n#\n\n############################# Server Basics #############################\n\n# The role of this server. Setting this puts us in KRaft mode\nprocess.roles=controller\n\n# The node id associated with this instance\'s roles\nnode.id=1\n\n# The connect string for the controller quorum\ncontroller.quorum.voters=1@kafka-controller-prd-001.com:9093,2@kafka-controller-prd-001.com:9093,3@kafka-controller-prd-001.com:9093\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on.\n# Note that only the controller listeners are allowed here when `process.roles=controller`, and this listener should be consistent with `controller.quorum.voters` value.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\nlisteners=CONTROLLER://kafka-controller-prd-001.com:9093\n\n# A comma-separated list of the names of the listeners used by the controller.\n# This is required if running in KRaft mode.\ncontroller.listener.names=CONTROLLER\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kraft-controller-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=2\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=2\ntransaction.state.log.replication.factor=2\ntransaction.state.log.min.isr=2\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\nlog.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n'})}),"\n",(0,r.jsx)(n.h4,{id:"controller2",children:"controller2"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the "License"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an "AS IS" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in KRaft mode, where\n# Apache ZooKeeper is not present.\n#\n\n############################# Server Basics #############################\n\n# The role of this server. Setting this puts us in KRaft mode\nprocess.roles=controller\n\n# The node id associated with this instance\'s roles\nnode.id=2\n\n# The connect string for the controller quorum\ncontroller.quorum.voters=1@kafka-controller-prd-001.com:9093,2@kafka-controller-prd-001.com:9093,3@kafka-controller-prd-001.com:9093\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on.\n# Note that only the controller listeners are allowed here when `process.roles=controller`, and this listener should be consistent with `controller.quorum.voters` value.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\nlisteners=CONTROLLER://kafka-controller-prd-002.com:9093\n\n# A comma-separated list of the names of the listeners used by the controller.\n# This is required if running in KRaft mode.\ncontroller.listener.names=CONTROLLER\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kraft-controller-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=2\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=2\ntransaction.state.log.replication.factor=2\ntransaction.state.log.min.isr=2\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\nlog.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n'})}),"\n",(0,r.jsx)(n.h4,{id:"controller3",children:"controller3"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the "License"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an "AS IS" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in KRaft mode, where\n# Apache ZooKeeper is not present.\n#\n\n############################# Server Basics #############################\n\n# The role of this server. Setting this puts us in KRaft mode\nprocess.roles=controller\n\n# The node id associated with this instance\'s roles\nnode.id=3\n\n# The connect string for the controller quorum\ncontroller.quorum.voters=1@kafka-controller-prd-001.com:9093,2@kafka-controller-prd-001.com:9093,3@kafka-controller-prd-001.com:9093\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on.\n# Note that only the controller listeners are allowed here when `process.roles=controller`, and this listener should be consistent with `controller.quorum.voters` value.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\nlisteners=CONTROLLER://kafka-controller-prd-003.com:9093\n\n# A comma-separated list of the names of the listeners used by the controller.\n# This is required if running in KRaft mode.\ncontroller.listener.names=CONTROLLER\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kraft-controller-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=2\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=2\ntransaction.state.log.replication.factor=2\ntransaction.state.log.min.isr=2\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\nlog.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n'})}),"\n",(0,r.jsx)(n.h3,{id:"broker",children:"broker"}),"\n",(0,r.jsxs)(n.p,{children:["\u8fd9\u91cc",(0,r.jsx)(n.code,{children:"broker"}),"\u4e2d\u7684\u914d\u7f6e\u4e5f\u662f",(0,r.jsx)(n.code,{children:"node.id"}),"\u548c",(0,r.jsx)(n.code,{children:"listeners"}),"\u4e0d\u4e00\u6837\uff0c\u5176\u6b21\u662f",(0,r.jsx)(n.code,{children:"node.id"}),"\u4e0d\u80fd\u548c",(0,r.jsx)(n.code,{children:"controller"}),"\u4e2d\u7684",(0,r.jsx)(n.code,{children:"node.id"}),"\u91cd\u590d\uff0c\u8981\u6574\u4e2a\u96c6\u7fa4\u552f\u4e00"]}),"\n",(0,r.jsx)(n.h4,{id:"broker1",children:"broker1"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the "License"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an "AS IS" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in KRaft mode, where\n# Apache ZooKeeper is not present.\n#\n\n############################# Server Basics #############################\n\n# The role of this server. Setting this puts us in KRaft mode\nprocess.roles=broker\n\n# The node id associated with this instance\'s roles\nnode.id=4\n\n# The connect string for the controller quorum\ncontroller.quorum.voters=1@kafka-controller-prd-001.com:9093,2@kafka-controller-prd-001.com:9093,3@kafka-controller-prd-001.com:9093\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\nlisteners=PLAINTEXT://kafka-prd-001.com:9092\n\n# Name of listener used for communication between brokers.\ninter.broker.listener.name=PLAINTEXT\n\n\n# A comma-separated list of the names of the listeners used by the controller.\n# This is required if running in KRaft mode. On a node with `process.roles=broker`, only the first listed listener will be used by the broker.\ncontroller.listener.names=CONTROLLER\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\nlistener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kraft-broker-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=2\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=2\ntransaction.state.log.replication.factor=2\ntransaction.state.log.min.isr=2\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\nlog.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\nauto.create.topics.enable=false\nmessage.max.bytes=10485760\n'})}),"\n",(0,r.jsx)(n.h4,{id:"broker2",children:"broker2"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the "License"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an "AS IS" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in KRaft mode, where\n# Apache ZooKeeper is not present.\n#\n\n############################# Server Basics #############################\n\n# The role of this server. Setting this puts us in KRaft mode\nprocess.roles=broker\n\n# The node id associated with this instance\'s roles\nnode.id=5\n\n# The connect string for the controller quorum\ncontroller.quorum.voters=1@kafka-controller-prd-001.com:9093,2@kafka-controller-prd-001.com:9093,3@kafka-controller-prd-001.com:9093\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\nlisteners=PLAINTEXT://kafka-prd-002.com:9092\n\n# Name of listener used for communication between brokers.\ninter.broker.listener.name=PLAINTEXT\n\n\n# A comma-separated list of the names of the listeners used by the controller.\n# This is required if running in KRaft mode. On a node with `process.roles=broker`, only the first listed listener will be used by the broker.\ncontroller.listener.names=CONTROLLER\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\nlistener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kraft-broker-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=2\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=2\ntransaction.state.log.replication.factor=2\ntransaction.state.log.min.isr=2\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\nlog.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\nauto.create.topics.enable=false\nmessage.max.bytes=10485760\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u90e8\u7f72",children:"\u90e8\u7f72"}),"\n",(0,r.jsx)(n.h3,{id:"1-\u5b89\u88c5jdk11",children:"1. \u5b89\u88c5jdk11"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"sudo apt update\napt install openjdk-11-jdk -y\n"})}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"5\u53f0\u673a\u5668\u6267\u884c"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-\u4e0b\u8f7dkafka\u4e8c\u8fdb\u5236\u5305",children:"2. \u4e0b\u8f7dkafka\u4e8c\u8fdb\u5236\u5305"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"wget http://mirrors.aliyun.com/apache/kafka/3.5.0/kafka_2.13-3.5.0.tgz\n"})}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"5\u53f0\u673a\u5668\u6267\u884c"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"3-\u89e3\u538b",children:"3. \u89e3\u538b"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"tar -xzf kafka_2.13-3.5.0.tgz\n"})}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"5\u53f0\u673a\u5668\u6267\u884c"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"4-\u7ed9\u96c6\u7fa4\u751f\u6210\u4e00\u4e2auuid",children:"4. \u7ed9\u96c6\u7fa4\u751f\u6210\u4e00\u4e2aUUID"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"kafka_2.13-3.0.0/bin/kafka-storage.sh random-uuid\n"})}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"\u5355\u53f0\u673a\u5668\u6267\u884c\u5373\u53ef"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["\u8fd9\u91cc\u6211\u751f\u6210\u7684UUID\u4e3a",(0,r.jsx)(n.code,{children:"mzXiaoZouNnbe32DRMpSkX"})]}),"\n",(0,r.jsx)(n.h3,{id:"5-\u4fee\u6539\u914d\u7f6e\u6587\u4ef6",children:"5. \u4fee\u6539\u914d\u7f6e\u6587\u4ef6"}),"\n",(0,r.jsxs)(n.p,{children:["1\u30012\u30013\u673a\u5668\u4fee\u6539controller\u914d\u7f6e\n\u5373",(0,r.jsx)(n.code,{children:"kafka_2.13-3.5.0/config/kraft/controller.properties"})]}),"\n",(0,r.jsxs)(n.p,{children:["4\u30015\u673a\u5668\u4fee\u6539\u914d\u7f6e",(0,r.jsx)(n.code,{children:"kafka_2.13-3.5.0/config/kraft/broker.properties"})]}),"\n",(0,r.jsx)(n.h3,{id:"6-\u542f\u52a8\u96c6\u7fa4",children:"6. \u542f\u52a8\u96c6\u7fa4"}),"\n",(0,r.jsx)(n.h4,{id:"\u542f\u52a8controller",children:"\u542f\u52a8controller"}),"\n",(0,r.jsxs)(n.p,{children:["\u6309\u987a\u5e8f\u4f9d\u6b21\u542f\u52a8\u96c6\u7fa4\u542f\u52a8",(0,r.jsx)(n.code,{children:"controller1"}),"\u3001",(0,r.jsx)(n.code,{children:"controller2"}),"\u3001",(0,r.jsx)(n.code,{children:"controller3"})]}),"\n",(0,r.jsx)(n.p,{children:"\u542f\u52a8\u6b65\u9aa4(\u6bcf\u4e2acontroller\u542f\u52a8\u90fd\u662f\u6267\u884c\u5982\u4e0b\u811a\u672c)"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"\u683c\u5f0f\u5316\u5b58\u50a8\u8def\u5f84"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"sh /home/ubuntu/kafka_2.13-3.5.0/bin/kafka-storage.sh format -t mzDehZx0RNmke27PRMpNkA  -c /home/ubuntu/kafka_2.13-3.5.0/config/kraft/controller.properties\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsx)(n.li,{children:"\u542f\u52a8"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:'export KAFKA_HEAP_OPTS="-Xmx11G -Xms11G"&&JMX_PORT=9988 nohup sh /data/kafka_2.13-3.5.0/bin/kafka-server-start.sh /data/kafka_2.13-3.5.0/config/kraft/controller.properties &\n'})}),"\n",(0,r.jsx)(n.h4,{id:"\u542f\u52a8broker",children:"\u542f\u52a8broker"}),"\n",(0,r.jsxs)(n.p,{children:["\u6309\u987a\u5e8f\u4f9d\u6b21\u542f\u52a8\u96c6\u7fa4\u542f\u52a8",(0,r.jsx)(n.code,{children:"broker1"}),"\u3001",(0,r.jsx)(n.code,{children:"broker2"})]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"\u683c\u5f0f\u5316\u5b58\u50a8\u8def\u5f84"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"sh /home/ubuntu/kafka_2.13-3.5.0/bin/kafka-storage.sh format -t mzDehZx0RNmke27PRMpNkA  -c /home/ubuntu/kafka_2.13-3.5.0/config/kraft/broker.properties\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsx)(n.li,{children:"\u542f\u52a8"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:'export KAFKA_HEAP_OPTS="-Xmx11G -Xms11G"&&JMX_PORT=9988 nohup sh /data/kafka_2.13-3.5.0/bin/kafka-server-start.sh /data/kafka_2.13-3.5.0/config/kraft/broker.properties &\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u63a5\u5165\u70b9",children:"\u63a5\u5165\u70b9"}),"\n",(0,r.jsx)(n.p,{children:"\u7531\u4e8e\u6211\u4eec\u4e4b\u524d\u8bbe\u7f6e\u4e86\u57df\u540d\uff0c\u6240\u4ee5\u6211\u4eec\u7684\u63a5\u5165\u70b9\u662f"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"kafka-prd-001.com:9092,kafka-prd-002.com:9092\n"})}),"\n",(0,r.jsx)(n.h2,{id:"\u5220\u9664\u5143\u6570\u636e",children:"\u5220\u9664\u5143\u6570\u636e"}),"\n",(0,r.jsx)(n.p,{children:"\u5982\u679c\u8981\u5220\u9664\u542f\u52a8\u7684\u5143\u6570\u636e\u91cd\u65b0\u90e8\u7f72"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"rm -rf /tmp/kafka-logs /tmp/kraft-controller-logs /tmp/kraft-combined-logs\n"})}),"\n",(0,r.jsx)(n.h2,{id:"\u6d4b\u8bd5",children:"\u6d4b\u8bd5"}),"\n",(0,r.jsxs)(n.p,{children:["\u6d4b\u63a7\u548c\u4e4b\u524d\u4e00\u6837 \u53ef\u4ee5\u53c2\u8003 ",(0,r.jsx)(n.a,{href:"https://weihubeats.blog.csdn.net/article/details/132736141",children:"Linux Kafka 3.5 KRaft\u6a21\u5f0f\u96c6\u7fa4\u90e8\u7f72"}),":",(0,r.jsx)(n.a,{href:"https://weihubeats.blog.csdn.net/article/details/132736141",children:"https://weihubeats.blog.csdn.net/article/details/132736141"})]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},28453(e,n,t){t.d(n,{R:()=>i,x:()=>a});var o=t(96540);const r={},s=o.createContext(r);function i(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);